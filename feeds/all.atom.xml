<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Joinmarket.me archive</title><link href="https://joinmarket.me/" rel="alternate"></link><link href="https://joinmarket.me/feeds/all.atom.xml" rel="self"></link><id>https://joinmarket.me/</id><updated>2020-06-15T00:00:00+02:00</updated><entry><title>The 445BTC gridchain case</title><link href="https://joinmarket.me/blog/blog/the-445-btc-gridchain-case/" rel="alternate"></link><published>2020-06-15T00:00:00+02:00</published><updated>2020-06-15T00:00:00+02:00</updated><author><name>Adam Gibson</name></author><id>tag:joinmarket.me,2020-06-15:/blog/blog/the-445-btc-gridchain-case/</id><summary type="html">&lt;h3&gt;The 445 BTC gridchain case&lt;/h3&gt;
&lt;p&gt;For those time-constrained or non-technical, it may make sense to read
only the &lt;a href="index.html#summary"&gt;Summary&lt;/a&gt; section of this article. It goes
without saying that the details do matter, and reading the other
sections will give you a much better overall picture.&lt;/p&gt;
&lt;h2&gt;Contents&lt;/h2&gt;
&lt;p&gt;&lt;a href="index.html#background"&gt;Background - what is the …&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;h3&gt;The 445 BTC gridchain case&lt;/h3&gt;
&lt;p&gt;For those time-constrained or non-technical, it may make sense to read
only the &lt;a href="index.html#summary"&gt;Summary&lt;/a&gt; section of this article. It goes
without saying that the details do matter, and reading the other
sections will give you a much better overall picture.&lt;/p&gt;
&lt;h2&gt;Contents&lt;/h2&gt;
&lt;p&gt;&lt;a href="index.html#background"&gt;Background - what is the "gridchain case"?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="index.html#change-peeling"&gt;Toxic change and peeling chains&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="index.html#change-joinmarket"&gt;Change outputs in a Joinmarket context&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="index.html#toxic-recall"&gt;The toxic recall attack&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="index.html#size-factor"&gt;The size factor&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="index.html#sudoku"&gt;Joinmarket sudoku&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="index.html#maker-taker"&gt;Reminder on the maker-taker tradeoff&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="index.html#address-reuse"&gt;Address reuse&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="index.html#summary"&gt;Summary; lessons learned; advice to users&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="index.html#already"&gt;Already implemented improvements&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="index.html#still-needed"&gt;Still needed improvements&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="index.html#recommendations"&gt;Recommendations for users&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="background"&gt;Background - what is the "gridchain case"?&lt;/h2&gt;
&lt;p&gt;This is a reflection on a case of reported theft as outlined
&lt;a href="https://old.reddit.com/r/Bitcoin/comments/69duq9/50_bounty_for_anybody_recovering_445_btc_stolen/"&gt;here&lt;/a&gt;
on reddit in early 2017 by user 'gridchain'.&lt;/p&gt;
&lt;p&gt;What I won't do here is discuss the practical details of the case;
things like, whether it was a hack or an inside job, nor anything like
network level metadata, all of which is extremely important in an actual
criminal investigation. But here I'm only focusing on the role played
by Joinmarket specifically and blockchain level activity of the coins,
generally.&lt;/p&gt;
&lt;p&gt;The reason for this blog post was
&lt;a href="https://research.oxt.me/the-cold-case-files/1"&gt;this&lt;/a&gt;
recent report by OXT Research - specifically by analyst
&lt;a href="https://bitcoinhackers.org/@ErgoBTC"&gt;ErgoBTC&lt;/a&gt;
(they require an email for signup to read the full report, otherwise you
only see the summary).&lt;/p&gt;
&lt;p&gt;A short note of thanks here to ErgoBTC and LaurentMT and others
involved, since this kind of detailed analysis is badly needed, I hope
will we see more, specifically in public, over time (we cannot hope for
such from the deeply unethical blockchain analysis companies).&lt;/p&gt;
&lt;p&gt;I'm [not]{style="text-decoration: underline;"} going to assume here
that you've read that report in full, but I am going to be referring to
its main set of conclusions, and analyzing them. Obviously if you want
to properly assess my statements, it's rather difficult - you'd need
full knowledge of Joinmarket's operation &lt;em&gt;and&lt;/em&gt; full details of the OXT
Research analysis - and even then, like me, you will still have some
significant uncertainties.&lt;/p&gt;
&lt;p&gt;So the case starts with the claimed theft in 2 parts: 45 BTC in &lt;a href="https://blockstream.info/tx/2f9bfc5f23b609f312faa60902022d6583136cc8e8a0aecf5213b41964963881"&gt;this
txn&lt;/a&gt;
(note I will use blockstream.info for my tx links because I find their
presentation easiest for single txs specifically; note that oxt.me 's
research tool is of course a vastly superior way to see a large network
of txs, which plays a crucial role in this analysis), and a
consolidation of 400BTC in &lt;a href="https://blockstream.info/tx/136d7c862267204c13fec539a89c7b9b44a92538567e1ebbce7fc9dd04c5a7f0"&gt;this other
txn&lt;/a&gt;
.&lt;/p&gt;
&lt;p&gt;We'll assume that both of these utxos are under the control of a single
actor/thief, henceforth just &lt;em&gt;A&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Setting aside the (in some ways remarkable) timing - that &lt;em&gt;A&lt;/em&gt; did not
move the coins for about 2 years - let's outline roughly what happened,
and what the report tells us:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The 400BTC went into joinmarket as a maker, and did a bunch (11 to
    be precise) of transactions that effectively "peeled down" (more
    on this later) that 400 to perhaps 335 BTC (with the difference
    going into coinjoins).&lt;/li&gt;
&lt;li&gt;&lt;em&gt;A&lt;/em&gt; then switched to a taker role for a while, focusing on higher
    denominations, ranging from \~ 6BTC to as high as \~58BTC. Many of
    these coinjoins had very low counterparty numbers (say 3-5 being
    typical).&lt;/li&gt;
&lt;li&gt;At some point some maker activity is seen again in this same
    "peeling chain"; the report terms this phase as "alternating",
    but it's hard to say for sure whether some particular script is
    running, whether &lt;em&gt;A&lt;/em&gt; is just randomly switching roles, or what.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Be aware that this simplified narrative suggests to the careless reader
that one can easily trace all the coins through all the coinjoins, which
of course is not true at all - each subsequent transaction moves some
portion into a "mixed state", but (a) we'll see later that just
"moved into mixed state" is not the end of the story for some of those
coins and (b) while this narrative is misleading for Joinmarket in
general, it is not &lt;em&gt;as&lt;/em&gt; misleading in this particular case.&lt;/p&gt;
&lt;p&gt;The distinction between the "second" and "third" phase as listed in
those bullet points is pretty much arbitrary, but what is not in doubt
as important is: that second phase marks a clear jump in coinjoin amount
average size (this could be read as impatience on &lt;em&gt;A&lt;/em&gt;'s part - but
that's just speculation), and this resulted in small anonymity sets in
some txs - 4 and 3 in two txs, in particular. Let's continue:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Within the second regime, the OXT analysis narrows in on those small
    anon set, large denomination txs - can they figure out which equal
    sized output belongs to &lt;em&gt;A&lt;/em&gt; here? The "toxic replay attack"
    (explained below) allows them to identify one coinjoin output
    unambiguously  - but that goes into another coinjoin. But in a
    second case it allows them to reduce the anonymity set (of the equal
    sized coinjoin outputs) to 2, and they trace forwards both of those
    outputs.&lt;/li&gt;
&lt;li&gt;One of those 2 coinjoin outputs (&lt;a href="https://blockstream.info/tx/2dc4e88685269795aafe7459087ab613878ce7d857dd35760eefeb9caf21371b"&gt;this
    txn&lt;/a&gt;
    , output index 2) pays, after several hops, into a Poloniex deposit
    address in &lt;a href="https://blockstream.info/tx/ab1e604cd959cc94b89ab02b691fe7d727d30637284e5e82908fb28b8db378f4"&gt;this
    txn&lt;/a&gt;
    ). Although this is several hops, and although it does not deposit
    all of that \~58BTC into Poloniex (only about half of it),
    nevertheless this can be (and is) treated as a significant lead.&lt;/li&gt;
&lt;li&gt;So the next step was to trace back from that specific Poloniex
    deposit address, which it turned out had a bunch of activity on it.
    See
    &lt;a href="https://blockstream.info/address/16vBEuZD54NzqnnSStPYxFF2aktGhhuaf1"&gt;16vBEuZD54NzqnnSStPYxFF2aktGhhuaf1&lt;/a&gt;
    . Indeed several other deposits to that single address are connected
    to the same Joinmarket cluster, and specifically connected to those
    smaller-anon set taker-side coinjoins. In total around 270BTC is
    eventually linked from &lt;em&gt;A&lt;/em&gt;'s joinmarket coinjoins to that deposit
    address. Even though some of those connections are ambiguous, due to
    address reuse the evidence of co-ownership appears very strong.&lt;/li&gt;
&lt;li&gt;Some further evidence is provided (though I am still fuzzy on the
    details, largely just because of the time needed to go through it
    all) linking more of the coins to final destinations, including some
    from the 45BTC original chunk. The claim is that 380BTC is linked at
    final destinations to the original 445BTC set. In the remainder
    I'll focus on what is already seen with this 270BTC set and only
    peripherally mention the rest - there is already a lot to chew on!&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="change-peeling"&gt;Toxic change and peeling chains&lt;/h2&gt;
&lt;p&gt;The general idea of a "peeling chain" on the Bitcoin blockchain isn't
too hard to understand. Given 100 BTC in a single utxo, if I have to
make a monthly payment of 1 BTC and never use my wallet otherwise, then
clearly the tx sequence is (using (input1, input2..):(output1,
output2..)) as a rudimentary format): ((100):(1,99), (99):(1, 98),
(98:(1, 97)...). Ignoring fees of course. What matters here is that I
just always have a single utxo and that on the blockchain &lt;em&gt;my&lt;/em&gt; utxos
&lt;em&gt;may&lt;/em&gt; be linked as (100-99-88-97...) based on a &lt;a href="https://en.bitcoin.it/wiki/Privacy#Change_address_detection"&gt;change
heuristic&lt;/a&gt;
such as "round amount for payment". To whatever extent change
heuristics work, then to that extent ownership can be traced through
simple payments (especially and mostly if transactions have exactly two
outputs, so that the very &lt;em&gt;idea&lt;/em&gt; of change, let alone a change
heuristic, applies straightforwardly).&lt;/p&gt;
&lt;p&gt;&lt;img alt="peeling chain simple
example" src="https://web.archive.org/web/20200713230834im_/https://joinmarket.me/static/media/uploads/.thumbnails/PeelingChain1.png/PeelingChain1-418x296.png"&gt;{width="418"
height="296"}&lt;/p&gt;
&lt;p&gt;In peeling chains, sometimes, the primary heuristic is the &lt;strong&gt;size&lt;/strong&gt; of
the output. If you start with 1000 btc and you peel 0.1 btc hundreds of
times, it's obvious from the "size pattern" what the change is (and
indeed it's this case that gives rise to the name &lt;em&gt;peel chain&lt;/em&gt; because
"peel" refers to taking off a &lt;em&gt;small&lt;/em&gt; part of something, usually its
surface). The above diagram is more similar (but not the same, exactly)
as the initial flow in the gridchain case, with one very large utxo
gradually getting peeled off.&lt;/p&gt;
&lt;p&gt;In some cases timing may factor in; sometimes hackers will do hundreds
of such peels off a main originating utxo in a short time.&lt;/p&gt;
&lt;p&gt;You can think of a peeling chain as the lowest effort ownership
obfuscation out there. Notice how literally any, even the simplest,
Bitcoin wallet, has to offer the feature required to carry this out -
just make a vanilla payment, for which there is (almost always, but not
always) a change output, back to your wallet.&lt;/p&gt;
&lt;p&gt;So in Bitcoin's history, this technique has very often been seen used -
by hackers/thieves moving coins "away" from the original site of the
theft (I remember the &lt;a href="http://www.techienews.co.uk/973470/silk-road-like-sheep-marketplace-scams-users-39k-bitcoins-worth-40-million-stolen/"&gt;case of Sheep
Market&lt;/a&gt;
for example). Each "peel" raises additional uncertainty; the
non-change output is going somewhere, but who owns that? But the change
outputs represent a link allowing someone, in theory, to keep tracing
the activity of the original actor. Notice here how we talk about one
branch (our ((100):(1,99), (99):(1, 98), (98:(1, 97)...) example
illustrates it); but one could keep tracing the payment outputs (the
'1's in that flow) and see if they themselves form other peel chains,
leading to a tree.&lt;/p&gt;
&lt;p&gt;We mentioned a 'change heuristic' element to this - which is the
"main branch" if we're not sure which output is the change?&lt;/p&gt;
&lt;h3 id="change-joinmarket"&gt;Change outputs in a Joinmarket context&lt;/h3&gt;
&lt;p&gt;A reader should from this point probably be familiar with the basics of
Joinmarket's design. Apart from the
&lt;a href="https://github.com/Joinmarket-Org/joinmarket-clientserver"&gt;README&lt;/a&gt;
and &lt;a href="hhttps://github.com/JoinMarket-Org/joinmarket-clientserver/blob/master/docs/USAGE.md"&gt;usage
guide&lt;/a&gt;
of the main Joinmarket code repo, the diagrams showing the main
Joinmarket transaction types
&lt;a href="https://github.com/AdamISZ/JMPrivacyAnalysis/blob/master/tumbler_privacy.md#joinmarket-transaction-types"&gt;here&lt;/a&gt;
may be useful as a refresher or a reference point for the following.&lt;/p&gt;
&lt;p&gt;We have: \(N\) equal outputs and \(N\) or \(N-1\) non-equal change
outputs, where \(N-1\) happens when the taker does a "sweep",
emptying the mixdepth (= account; joinmarket wallets have 5 accounts by
default) without a change output. [This last feature is specific to
Joinmarket, and specific to the taker role: there's no other coinjoin
out there that provides the facility to sweep an arbitrary amount of
coins out to an equal-sized output, with no
change.]{style="text-decoration: underline;"} (I am emphasizing this not
for marketing, but because it's crucial to this topic, and not widely
understood I think).&lt;/p&gt;
&lt;p&gt;As an example of why it's important, here is one line from the OXT
Research article:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Fees taken directly in a mix transaction result in deterministic
links ("unmixed change").&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is false as an absolute statement; fees can be paid by a taker,
inside the transaction, with no unmixed change for the taker (this is
the Joinmarket 'sweep'). Deterministic links between inputs and change
outputs &lt;em&gt;do&lt;/em&gt; result from change, and fees &lt;em&gt;do&lt;/em&gt; create an additional flag
that can help make those linkages, in cases where there would be more
ambiguity. But a zero fee coinjoin with change outputs still has
deterministic links, usually.&lt;/p&gt;
&lt;p&gt;Why does the OXT Research article heavily focus on &lt;em&gt;toxic unmixed
change&lt;/em&gt; as a concept and as a key weakness of such protocols as
Joinmarket, and why do I disagree?&lt;/p&gt;
&lt;p&gt;As we discussed peeling chains offer a low quality of obfuscation, and
to unpack that: the problem is that if you have any relatively viable
change heuristic (it doesn't &lt;em&gt;have&lt;/em&gt; to be large amounts as discussed),
it can let you keep knowledge of ownership of a whole chain of
transactions. That basically gives the blockchain analyst (we'll call
&lt;em&gt;B&lt;/em&gt;) a very large attack surface. He can look at &lt;em&gt;all&lt;/em&gt; the information
flowing out of, or associated with, a whole chain of transactions. Any
later recombination of outputs from that "large attack surface" is
either a coinjoin or a "smoking gun" that different outward paths were
actually under the control of one owner (this comes back to that central
heuristic - common input ownership, and all the nuance around that).&lt;/p&gt;
&lt;p&gt;In Joinmarket or any other coinjoin protocol that does allow change
outputs, "change heuristic" doesn't really apply, it kind of morphs
into something else: it's very obvious which outputs are change, but it
is only &lt;em&gt;in some cases&lt;/em&gt; easy to disentangle which change outputs are
associated to which inputs, and that's actually what you need to know
if you want to trace via the change (as per "peeling chains"
description above). In high anonymity sets, it starts to get difficult
to do that disentangling, but more on that ("sudoku") later.&lt;/p&gt;
&lt;p&gt;The analysis done in the OXT Research report smartly combines a long
peeling chain with other specific weaknesses in the way &lt;em&gt;A&lt;/em&gt; acted, which
we will discuss in the next section.. So all this is very valid in my
view.&lt;/p&gt;
&lt;p&gt;[But I think going from the above to the conclusion "coinjoins which
have unmixed change are fundamentally inferior and not viable, compared
to coinjoins without unmixed change" is just flat out
wrong]{style="text-decoration: underline;"}. Consider yourself in the
position of &lt;em&gt;A&lt;/em&gt;. You have let's say 400BTC in a single utxo. If you run
a coinjoin protocol that insists on no change always, and without a
market mechanism, you are forced to use a fixed denomination, say 0.1
BTC (an example that seems common), now across thousands of
transactions. In order to create these fixed denomination utxos you are
faced with the same problem of trying to avoid a trivial peeling chain.
By insisting on no deterministic links within the coinjoin, you simply
move the problem to an earlier step, you do not remove it.&lt;/p&gt;
&lt;p&gt;Fixed denomination does not solve the problem of having an unusually
large amount to mix compared to your peers.&lt;/p&gt;
&lt;p&gt;Having said that, fixed denomination with no change at all, does create
other advantages - I certainly don't mean to disparage that model!
Without going into detail here, consider that a large set or network of
all-equal-in all-equal-out coinjoins can create similar effects to a
single, much larger, coinjoin (but this is a topic for another article).&lt;/p&gt;
&lt;h2 id="toxic-recall"&gt;The toxic recall attack&lt;/h2&gt;
&lt;p&gt;Earlier we explained that one of the steps of the OXT Research analysis
was to identify a low liquidity regime where &lt;em&gt;A&lt;/em&gt; was acting as taker,
and we mentioned the "toxic recall attack" was used to reduce the
anonymity sets of the coinjoin outputs, during this, to a level low
enough that simple enumeration could find good candidates for final
destinations of those coins.&lt;/p&gt;
&lt;p&gt;Embedded in this was a crucial piece of reasoning, and I think this was
a both excellent, and very important idea:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Joinmarket does not allow co-spending of utxos from different
    accounts&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;That means that if a coinjoin output &lt;em&gt;X&lt;/em&gt; is spent along with a utxo
    from the "peeling chain" (i.e. they are both inputs to the same
    tx), then &lt;em&gt;X&lt;/em&gt; is not owned by &lt;em&gt;A&lt;/em&gt; (assuming correct identification
    of &lt;em&gt;A&lt;/em&gt;'s peeling chain)&lt;/li&gt;
&lt;li&gt;Every time such an event occurs, that &lt;em&gt;X&lt;/em&gt; can be crossed off the
    list of coinjoin outputs that &lt;em&gt;A&lt;/em&gt; might own, thus reducing the
    anonymity set of that earlier coinjoin by 1.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The reasoning is not perfectly watertight:&lt;/p&gt;
&lt;p&gt;First, as the report observes: the first assumption behind it is "A
user can only run one mixing client at a time." This is clearly not
literally true, but like many things here, a good-enough guess is fine,
if it eventually leads to outcomes that further strengthen the case. And
that is definitely true here: while a smart operator probably would be
running more than one instance of Joinmarket code, it is not default
behaviour and requires both a little coding and some careful thought.
Most people would not do this.&lt;/p&gt;
&lt;p&gt;(Second, nothing stops a user from making a coinjoin to an address in
the same mixdepth (at least in the current software). It's just that
(a) that is heavily discouraged and (b) it's not easy to see a good
reason why someone would &lt;em&gt;try&lt;/em&gt; to do that. Still it is possible as a
mistake. But I don't think this is a reason to doubt the effectiveness
of the "toxic recall attack", just, it should be noted.)&lt;/p&gt;
&lt;p&gt;So overall the bolded sentence is the most interesting - Joinmarket's
intention is to prevent co-spending outputs which would ruin the effect
of any single coinjoin - i.e. it tries (caveat: above parenthetical) to
prevent you using both a coinjoin output and the change output (or any
other utxo in the same account as the change output and the original
inputs) together. And this small element of 'rigidity' in how coins
are selected for spending is actually another 'bit' of information
that &lt;em&gt;B&lt;/em&gt; can use to make deductions, at least some of the time.&lt;/p&gt;
&lt;p&gt;The following diagram tries to illustrate how these conditions lead to
the possibility of the attack, to reduce the anonymity set of coinjoin
outputs:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Toxic recall attack
illustration" src="https://web.archive.org/web/20200713230834im_/https://joinmarket.me/static/media/uploads/.thumbnails/ToxicRecall1.png/ToxicRecall1-692x490.png"&gt;{width="692"
height="490"}&lt;/p&gt;
&lt;p&gt;So in summary we see 4 really important factors leading to the attack's
viability:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Joinmarket's strict account separation&lt;/li&gt;
&lt;li&gt;Linkability via change - as we'll describe in the next section
    "Joinmarket sudoku", this is &lt;em&gt;usually&lt;/em&gt; but not always possible, so
    while (1) was 99% valid this is more like 75% valid (entirely vague
    figures of course).&lt;/li&gt;
&lt;li&gt;Reusing the same peers in different coinjoin transactions&lt;/li&gt;
&lt;li&gt;Low number of peers&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Of course, 3 and 4 are closely tied together; reuse of peers happened a
lot precisely because there were so few peers available for large
coinjoin sizes (to remind you, it was between 6 and 58 BTC, and the
average was around 27, and there are/were few Joinmarket peers actually
offering above say 10BTC).&lt;/p&gt;
&lt;h2 id="size-factor"&gt;The size factor&lt;/h2&gt;
&lt;p&gt;This is a thread that's run through the above, but let's be clear
about it: in practice, typical Joinmarket coinjoins run from 0.1 to 10
BTC, which is unsurprising. There are a fair number of much smaller
transactions, many just functioning as tests, while &lt;em&gt;really&lt;/em&gt; small
amounts are not very viable due to the fees paid by the taker to the
bitcoin network. Larger than 10 BTC are certainly seen, including up to
50 BTC and even beyond, but they appear to be quite rare.&lt;/p&gt;
&lt;p&gt;The actions of &lt;em&gt;A&lt;/em&gt; in this regard were clearly suboptimal. They started
by taking 4 x 100 BTC outputs and consolidating them into 1 output of
400 BTC. This was not helpful, if anything the opposite should have been
done.&lt;/p&gt;
&lt;p&gt;Second, as a consequence, they placed the entirety of this (I'm
ignoring the 45 BTC output for now as it's not that crucial) in one
mixdepth. For smaller amounts where a user is just casually offering
coins for joining, one output is fine, and will rapidly be split up
anyway, but here this very large size [led to most of the large-ish
joining events forming part of one long peeling
chain&lt;em&gt;.&lt;/em&gt;]{style="text-decoration: underline;"} This part probably isn't
clear so let me illustrate. A yield generator/maker usually splits up
its coins into random chunks pretty quickly, and while as a maker they
do &lt;strong&gt;not&lt;/strong&gt; get the crucial "sweep, no change" type of transaction
mentioned above, they nevertheless do get fragmentation:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Initial deposit --&amp;gt; After 1 tx --&amp;gt; After 2 txs --&amp;gt; After many txs&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;0: 1BTC         --&amp;gt; 0.800 BTC  --&amp;gt; 0.800 BTC   --&amp;gt; 0.236 BTC&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;1: 0 BTC        --&amp;gt; 0.205 BTC  --&amp;gt; 0.110 BTC   --&amp;gt; 0.001 BTC&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;2: 0 BTC        --&amp;gt; 0.000 BTC  --&amp;gt; 0.100 BTC   --&amp;gt; 0.555 BTC&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;3: 0 BTC        --&amp;gt; 0.000 BTC  --&amp;gt; 0.000 BTC   --&amp;gt; 0.129 BTC&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;4: 0 BTC        --&amp;gt; 0.000 BTC  --&amp;gt; 0.000 BTC   --&amp;gt; 0.107 BTC&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;(Final total is a bit more than 1BTC due to fees; the reason it gets
jumbled, with no ordering, is: each tx moves coinjoin output to &lt;em&gt;next&lt;/em&gt;
mixdepth, mod 5 (ie it wraps), but when a new tx request comes in it
might be for any arbitrary size, so the mixdepth used as &lt;em&gt;source&lt;/em&gt; of
coins for that next transaction, could be any of them. This is
illustrated in the 'after 2 txs' case: the second mixdepth was chosen
as input to the second tx, not the first mixdepth).&lt;/p&gt;
&lt;p&gt;This dynamic does &lt;strong&gt;not&lt;/strong&gt; remove the "peeling chain" or "toxic
change" dynamic emphasized in OXT Research's report - because every tx
done by the maker still has its change, [precisely because as maker you
don't have the privilege of choosing the
amount]{style="text-decoration: underline;"}.&lt;/p&gt;
&lt;p&gt;But it does result in more so to speak "parallelisation" of the mixing
activity, instead of the largest chunk all being in one long chain.&lt;/p&gt;
&lt;p&gt;A question remains, if we imagine that we use much smaller amounts - can
the analyst always follow the "peeling chain of each mixdepth" (to
coin a phrase which at this point hopefully makes sense)?&lt;/p&gt;
&lt;p&gt;I think actually the answer is more 'no' than you might at first
think. The next section will illustrate.&lt;/p&gt;
&lt;h2 id="sudoku"&gt;Joinmarket sudoku.&lt;/h2&gt;
&lt;p&gt;This concept including its origination is covered in some detail in my
earlier article
&lt;a href="https://github.com/AdamISZ/JMPrivacyAnalysis/blob/master/tumbler_privacy.md#jmsudoku-coinjoin-sudoku-for-jmtxs"&gt;here&lt;/a&gt;.
Essentially we are talking about making unambiguous linkages between
change outputs and the corresponding inputs in any given Joinmarket
coinjoin. I reproduce one transaction diagram from that article here to
help the reader keep the right idea in mind:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Coinjoin
canonical" src="https://web.archive.org/web/20200713230834im_/https://joinmarket.me/static/media/uploads/cjmtx.svg"&gt;{width="550"
height="389"}&lt;/p&gt;
&lt;p&gt;So to effect this "sudoku" or disentangling, let's suppose you don't
have any sophistication. You're just going to iterate over every
possible subset of the inputs (they're randomly ordered, of course) and
see if it matches any particular change output (you assume that there is
exactly one change output per participant). In case it wasn't obvious,
"matches" here means "that change output, plus the coinjoin size (3
btc in the diagram above), equals the sum of the subset of inputs".&lt;/p&gt;
&lt;p&gt;Now none of them will &lt;em&gt;actually&lt;/em&gt; match because there are fees of two
types being paid out of (and into) the change - the bitcoin network fees
and the coinjoin fees (which add to most and subtract from one, at least
usually). So since you don't know the exact values of those fees, only
a general range, you have to include a "tolerance" parameter, which
really complicates the issue.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://gist.github.com/AdamISZ/15223a5eab940559e5cf55e898354978"&gt;This
gist&lt;/a&gt;
is a quick and dirty (in the sense it's barely a 'program' since i
just hardcoded the values of the transaction) example of doing such a
Joinmarket sudoku for one of the transactions in the OXT Research
analysis of flows for this case. The pythonistas out there might find of
interest particularly this code snippet for finding the "power set"
(the set of all subsets):&lt;/p&gt;
&lt;p&gt;&lt;code&gt;def power_set(l):&lt;/code&gt;\
&lt;code&gt;iil = range(len(l))&lt;/code&gt;\
&lt;code&gt;return list(chain.from_iterable(combinations(iil, r) for r in range(len(iil)+1)))&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;As per a very beautiful piece of mathematical reasoning, the power set
of a set of size \(N\) is \(2\^{N}\) (every member of set is either
in, or not in, each subset - think about it!). So this matters because
it illustrates, crudely, how we have here an exponential blowup.&lt;/p&gt;
&lt;p&gt;That particular transaction had 24 inputs, so the power set's
cardinality would be \(2\^{24}\) - but the beginning of the analysis
is to take a subset, of size 4, you already conclude to be linked, thus
reducing the size of the search space by a factor of 16. Now, there's a
lot more to it, but, here's what's interesting: &lt;strong&gt;depending on the
tolerance you choose, you will often find there are multiple sudoku
solutions&lt;/strong&gt; if the size of the set of inputs is reasonably large (let's
say 20 and up, but it isn't possible to fix a specific number of
course). In the first couple of attempts of finding the solution for
that transaction, I found between 3 and 7 different possible ways the
inputs and outputs could connect; some of them involve the pre-grouped 4
inputs acting as taker (i.e. paying fees) and some involve them acting
as maker.&lt;/p&gt;
&lt;p&gt;Now, if this ambiguity isn't enough, there's another significant
source of ambiguity in these sudokus: previous equal-sized coinjoin
outputs. For example take &lt;a href="https://blockstream.info/tx/5f8747a3837a56dd2f422d137b96b1420fd6885be6d1057f3c4dca102a3138b6?output:5"&gt;this
txn&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img alt="un-sudoku-able
tx" src="https://web.archive.org/web/20200713230834im_/https://joinmarket.me/static/media/uploads/.thumbnails/tx5f8747.png/tx5f8747-849x617.png"&gt;{width="849"
height="617"}&lt;/p&gt;
&lt;p&gt;There are 21 inputs, which is already in the "problematic" zone for
sudoku-ing, as discussed, in that it will tend to lead to multiple
possible solutions, with a reasonable tolerance parameter. But in this
case a full sudoku is fundamentally impossible: notice that inputs index
7 and 21 (counting from 0) both have amount 6.1212 . This means that any
subset that includes the first is identical to a subset that includes
the second. Those two outputs are, unsurprisingly, from the same
previous Joinmarket coinjoin (they don't have to be, though).&lt;/p&gt;
&lt;p&gt;In any long "peeling chain" these ambiguities will degrade, perhaps
destroy, the signal over time - unless there is some very strong
watermark effect - such as huge size, which is precisely what we see
with &lt;em&gt;A&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;To summarize, we these key points about the Sudoku concept for
identifying chains of ownership:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;As long as you don't sweep, a Joinmarket account, thus not emptied,
    will keep creating this chain of ownership via change - though the
    size of that linked amount dwindles over time.&lt;/li&gt;
&lt;li&gt;Thus makers (who cannot sweep) have no guarantee of not having that
    specific ownership trace persist, for each of their 5 accounts (but
    &lt;em&gt;not&lt;/em&gt; across them - the 5 accounts will not be connected on chain,
    at least not in a trivial way).&lt;/li&gt;
&lt;li&gt;If you use a very large size then this acts as a strong enough
    watermark that such tracing is pretty much guaranteed to work (i.e
    the Sudoku works much more reliably if you put in a 400BTC utxo and
    everyone else in the coinjoin only uses 10BTC at max).&lt;/li&gt;
&lt;li&gt;Otherwise, and in general, such tracing is a bit unreliable, and
    over a long series of transactions it becomes very unreliable (but
    again - this is no kind of privacy guarantee! - we just observe that
    there will be increasing uncertainty over a long chain, including
    really fundamental ambiguities like the transaction above).&lt;/li&gt;
&lt;li&gt;Whenever you &lt;em&gt;do&lt;/em&gt; sweep, you create what I called in the previous
    article a &lt;a href="https://github.com/AdamISZ/JMPrivacyAnalysis/blob/master/tumbler_privacy.md#joinmarket-wallet-closures"&gt;"completed mixdepth
    closure"&lt;/a&gt;;
    there is no change for you as taker, and so an end to that
    "chain". This only exists for takers. (you can of course sweep
    &lt;em&gt;without&lt;/em&gt; coinjoin at all, also).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="maker-taker"&gt;Reminder on the maker-taker tradeoff&lt;/h3&gt;
&lt;p&gt;This illustrates another aspect of the more general phenomenon -
Joinmarket almost by definition exists to serve takers. They pay for
these advantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;As coordinator, they do not reveal linkages to their counterparties.
    Makers must accept that the taker in each individual coinjoin &lt;em&gt;does&lt;/em&gt;
    know &lt;em&gt;their&lt;/em&gt; linkages (the maker's), even if they're OK with that
    over a long period because there are many disparate takers; that's
    a weakness.&lt;/li&gt;
&lt;li&gt;They choose the time when the coinjoin happens (within a minute or
    so, it's done, if all goes well)&lt;/li&gt;
&lt;li&gt;They choose the amount of the coinjoin, so can have a payment as a
    coinjoin outpoint.&lt;/li&gt;
&lt;li&gt;Corollary of the above: they can control the size of their change,
    in particular, reducing it to zero via a "sweep"&lt;/li&gt;
&lt;li&gt;Since they run only when they want to coinjoin, they have a smaller
    time footprint for attackers (makers have an "always on hot
    wallet" &lt;em&gt;which responds to requests rather than initiates them&lt;/em&gt; ,
    so it's more like a server than a client, which is by definition
    difficult to keep properly secure).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These 4+ advantages are what the Taker pays for, and it's interesting
that in practice that the &lt;em&gt;coinjoin&lt;/em&gt; fee has fallen to near-zero
&lt;strong&gt;except for larger sizes&lt;/strong&gt; .I will point to my earlier thoughts on low
fees
&lt;a href="https://x0f.org/web/statuses/104123055565241054"&gt;here&lt;/a&gt;
to avoid further sidetrack.&lt;/p&gt;
&lt;p&gt;Therefore the cool sounding idea "oh I have this bunch of bitcoin
sitting around, I'll just passively mix it for a while and actually get
paid to do it!" (I have noticed people &lt;em&gt;mostly&lt;/em&gt; get interested in
Joinmarket from this perspective) is more limited than it seems.&lt;/p&gt;
&lt;h2&gt;Address reuse&lt;/h2&gt;
&lt;p&gt;This will probably be the shortest section because it's so obvious.&lt;/p&gt;
&lt;p&gt;The fact that 270BTC of the 445 BTC going "into" Joinmarket ended up
at &lt;code&gt;16vBEuZD54NzqnnSStPYxFF2aktGhhuaf1&lt;/code&gt;is kind of a big facepalm moment;
I don't think anyone reading this blog would have trouble understanding
that.&lt;/p&gt;
&lt;p&gt;I don't dismiss or ignore that such things happen for a reason, and
that reason is mainly actions of centralized exchanges to deliberately
reduce the privacy of their customers ("KYC/AML"). Sometimes, of
course, sheer incompetence is involved. But it's the exception rather
than the rule, since even the most basic consumer wallets do not
generally reuse addresses nowadays. I'll consider these real world
factors out-of-scope of this article, although they will matter in your
practical real life decisions about keeping your privacy (consider &lt;em&gt;not&lt;/em&gt;
using such exchanges).&lt;/p&gt;
&lt;p&gt;What has to be said though: 270 does not equal 445 (or 400); it is not
impossible to imagine that such a set of deposits to one address may not
be traced/connected to the original deposit of 400 (+) into Joinmarket
(although it would really help if that total wasn't so very large that
there are only a few Joinmarket participants in that range anyway). And
indeed, my own examination of the evidence tells me that the connections
of each individual final deposit to
`16vBEuZD54NzqnnSStPYxFF2aktGhhuaf1```back to that original 445 is &lt;em&gt;not&lt;/em&gt;
unambiguous. The problem is of course the compounding effect of
evidence, as we will discuss in the next, final section.&lt;/p&gt;
&lt;h2 id="summary"&gt;Summary; lessons learned; advice to users&lt;/h2&gt;
&lt;p&gt;So we've looked into details, can we summarize what went wrong for &lt;em&gt;A&lt;/em&gt;?
Albeit we don't actually know with certainty how much of the
attributions in the OXT Research are correct, they appear to be &lt;em&gt;broadly
correct&lt;/em&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;400 BTC is a very large amount to move through a system of perhaps
    at best a couple hundred users (100 makers on the offer at once is
    typical), most of whom are not operating with more than 10 BTC.&lt;/li&gt;
&lt;li&gt;One large chunk of 400 is therefore a way worse idea than say 10
    chunks of 40 across 10 Joinmarket wallets (just common sense really,
    although starting with 400 is not in itself a disaster, it just
    makes it harder, and slower). This would have been more hassle, and
    more fees, but would have helped an awful lot.&lt;/li&gt;
&lt;li&gt;Running passively as a maker proved too slow for &lt;em&gt;A&lt;/em&gt; (this is an
    assumption that the report makes and that I agree with, but not of
    course a 'fact'). This is Joinmarket's failing if anything; there
    are just not enough people using it, which relates to the next
    point:&lt;/li&gt;
&lt;li&gt;When switching to a taker mode (which in itself was a very good
    idea), &lt;em&gt;A&lt;/em&gt; decided to start doing much larger transaction sizes, but
    found themselves unable to get more than a few counterparties in
    some cases. This should have been a sign that the effect they were
    looking for might not be strong enough, but it's very
    understandable that they didn't grok the next point:&lt;/li&gt;
&lt;li&gt;The "toxic replay attack" very heavily compounds the low anonymity
    set problem mentioned above - reuse of the same counterparties in
    successive transactions reduced the anonymity set from "bad" to
    "disastrously low" (even down to 1 in one case).&lt;/li&gt;
&lt;li&gt;Even with the above failings, all needn't really be lost; repeated
    rounds are used and the '1' anonymity set mentioned output was
    sent to another coinjoin anyway. The first chunk of coins identified
    to be sent to Poloniex address (first to be identified, not first in
    time) was in an amount of about 28 BTC via several hops, then part
    of the 76 BTC in &lt;a href="https://web.archive.org/web/20200713230834/https://joinmarket.me/blog/blog/the-445-btc-gridchain-case/%22https://blockstream.info/tx/ab1e604cd959cc94b89ab02b691fe7d727d30637284e5e82908fb28b8db378f4"&gt;this
    txn&lt;/a&gt;,
    and even the first hop only had a 50% likelihood assigned. So it's
    a combination of (a) the address being marked as in the POLONIEX
    cluster, the size of the deposit and then the reuse allowing tracing
    back to other transactions, that caused a "high-likelihood
    assignment of ownership", which leads into ...&lt;/li&gt;
&lt;li&gt;Address reuse as discussed in the previous section is the biggest
    failing here. If all the deposits here were to different exchange
    addresses, these heuristics would not have led to any clear
    outcomes. A few guesses here and there would exist, but they would
    remain guesses, with other possibilities also being reasonable.&lt;/li&gt;
&lt;li&gt;Circling back to the beginning, notice how making educated guesses
    about deposits on exchanges a few hops away from Joinmarket might
    already be enough to get some decent guesses at ownership, if the
    sizes are large enough compared to the rest of the Joinmarket usage.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So overall the post mortem is: &lt;strong&gt;a combination of at least three
different things leads to a bad outcome for &lt;em&gt;A&lt;/em&gt; : large (much bigger
than typical JM volume) size not split up, heavy address reuse (on a
centralized exchange) and a small anonymity set portion of the
sequence.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This issue of "combination of factors" leading to a much worse than
expected privacy loss is explained well on the bitcoin wiki Privacy page
&lt;a href="https://en.bitcoin.it/wiki/Privacy#Method_of_data_fusion"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="already"&gt;Already implemented improvements&lt;/h3&gt;
&lt;p&gt;When running as a taker and using the so-called &lt;a href="https://github.com/JoinMarket-Org/joinmarket-clientserver/blob/master/docs/tumblerguide.md"&gt;tumbler
algorithm&lt;/a&gt;
users should note that in 2019 a fairly meaningful change to the
algorithm was implemented - one part was to start each run with a sweep
transaction out of each mixdepth containing coins as the first step
(with longer randomized waits). This makes a peeling chain direct from a
deposit not possible (you can always try to guess which coinjoin output
to hop to next of course, with the concomitant difficulties).
Additionally average requested anonymity sets are increased, which, as
an important byproduct tends to create larger input sets which are
harder to sudoku (and more likely to have substantial ambiguity). There
are several other minor changes like rounding amounts, see &lt;a href="https://gist.github.com/chris-belcher/7e92810f07328fdfdef2ce444aad0968"&gt;Chris
Belcher's document on
it&lt;/a&gt;
for more details.&lt;/p&gt;
&lt;h3 id="still-needed"&gt;Still needed improvements&lt;/h3&gt;
&lt;p&gt;Clearly the toxic recall attack concept matters - it is going to matter
more, statistically, as the anonymity set (i.e. the number of coinjoin
counterparties) is reduced, but it matters per se in any context -
reusing the same counterparties &lt;strong&gt;&lt;em&gt;in a sequence of coinjoins from the
same mixdepth closure&lt;/em&gt;&lt;/strong&gt; reduces the anonymity set. Notice there are a
couple of ways that situation could be remediated:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Reduce the number of coinjoin transactions within the same mixdepth
    closure - but this is not clear. If I do 1 coinjoin transaction with
    10 counterparties and it's a sweep, closing the mixdepth closure,
    is that better than doing 2 coinjoin transactions from it, each of
    which has 6 counterparties, if there is a 10% chance of randomly
    choosing the same counterparty and thus reducing the anonymity set
    of the second coinjoin by 1? That is pretty profoundly unclear and
    seems to just "depend". 1 transaction with 12 counterparties &lt;em&gt;is&lt;/em&gt;
    clearly better, but very large sets like that are very difficult to
    achieve in Joinmarket today (particularly if your coinjoin amount is
    large).&lt;/li&gt;
&lt;li&gt;Actively try to prevent reusing the same counterparty for multiple
    transactions in the same mixdepth closure (obviously this is for
    takers; makers are not choosing, they are offering). Identification
    of bots is problematic, so probably the best way to do this is
    simply for a taker to keep track of its earlier txs (especially
    within a tumbler run, say) and decide to not include makers when
    they provide utxos that are recognized as in that set. This is still
    a bit tricky in practice; makers don't want their utxos queried all
    the time, but takers for optimal outcomes would like full
    transparent vision into those utxo sets - see &lt;a href="https://web.archive.org/web/20200713230834/https://joinmarket.me/blog/blog/poodle/"&gt;earlier discussion of
    PoDLE&lt;/a&gt;
    and
    &lt;a href="https://web.archive.org/web/20200713230834/https://joinmarket.me/blog/blog/racing-against-snoopers-in-joinmarket-02/"&gt;here&lt;/a&gt;
    on this blog for the tricky points around this.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;(2) is an example of ideas that were discussed by Joinmarket
developers years ago, but never really went anywhere. Takers probably
&lt;em&gt;should&lt;/em&gt; expand the query power given them by the PoDLE tokens to have a
larger set of options to choose from, to gauge the "quality" of what
their counterparties propose as join inputs, but it's a delicate
balancing act, as mentioned.&lt;/p&gt;
&lt;h3 id="recommendations"&gt;Recommendations for users&lt;/h3&gt;
&lt;p&gt;For the final section, some practical advice. Joinmarket can be a
powerful tool - but it's unfortunately not very easy to understand what
you &lt;em&gt;should&lt;/em&gt; do, precisely because there is a lot of flexibility.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The taker role, and in particular the tumbler role, are designed to
    be used to actively improve your privacy. We explain above that it
    gives certain advantages over the maker role. So: &lt;strong&gt;use it!&lt;/strong&gt; - with
    at least the default settings for counterparty numbers and
    transaction numbers, and long waits - in fact, increase these
    factors above the defaults. Note that tumbles can be safely
    restarted, so do it for a day, shut it down and then restart it a
    few days later - that's fine. See the docs for more on that. Be
    sensitive to bitcoin network fees - these transactions are very
    large so they'll be more palatable at times when the network is
    clearing 1-5 sats/byte. However ...&lt;/li&gt;
&lt;li&gt;... mixing roles definitely has advantages. The more people mix
    roles the more unsafe it is to make deductions about which coinjoin
    output belonged to the taker, after it gets spent (consider what you
    can deduce about a coinjoin output which is then spent via an
    ordinary wallet, say to a t-shirt merchant).&lt;/li&gt;
&lt;li&gt;The maker role isn't useless for privacy, it's rather best to
    think of it as (a) limited and (b) taking a long time to have an
    effect. It's most suitable if your threat model is "I don't want
    a clear history of my coins over the long term". It also costs
    nothing monetarily and brings in some very small income if your size
    is large (if small, it's likely not worth mentioning) - but in that
    case, take your security seriously.&lt;/li&gt;
&lt;li&gt;Consider sizing when acting as a taker. We as a project should
    perhaps create more transparency around this, but you can gauge from
    your success in arranging big size coinjoins: if you can't easily
    find 6+ counterparties to do a coinjoin at a particular size, it may
    not be a good idea to rely on the outcomes, as you may be mixing in
    too small of a crowd (whether that's at 10 BTC or 20 BTC or 50+ BTC
    just depends on market condition).&lt;/li&gt;
&lt;li&gt;Make good use of (a) the accounts (mixdepths) feature, (b) the coin
    freeze feature and (c) the sweep feature (taker only). These three
    things allow you to better isolate coins going to different
    destinations - your cold wallet, your mobile spending wallet, an
    exchange etc etc. Accounts let you have the assurance that coins in
    one aren't linked with coins in another; you can't accidentally
    co-spend them. The freeze feature (see the "Coins" tab on Qt) lets
    you spend individual utxos, where that's important to you for some
    reason, without connection to others. And the sweep feature lets you
    make a coinjoin without any change, breaking a link to future
    transactions.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We soon (in 0.7.0; the code is basically already done) hope to have more
helpful features, in particular Payjoin as defined in BIP 78, along with
very basic PSBT support.&lt;/p&gt;</content><category term="waxwing's Blog"></category><category term="coinjoin"></category><category term="joinmarket"></category><category term="bitcoin"></category></entry><entry><title>Ring Signatures</title><link href="https://joinmarket.me/blog/blog/ring-signatures/" rel="alternate"></link><published>2019-03-15T00:00:00+01:00</published><updated>2019-03-15T00:00:00+01:00</updated><author><name>Adam Gibson</name></author><id>tag:joinmarket.me,2019-03-15:/blog/blog/ring-signatures/</id><summary type="html">&lt;h3&gt;Ring signatures&lt;/h3&gt;
&lt;h2&gt;Outline:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Basic goal of 1-of-\(N\) ring signatures&lt;/li&gt;
&lt;li&gt;Recap: the \(\Sigma\)-protocol&lt;/li&gt;
&lt;li&gt;OR of \(\Sigma\)-protocols, CDS 1994&lt;/li&gt;
&lt;li&gt;Abe-Ohkubo-Suzuki (AOS) 2002 (broken version)&lt;/li&gt;
&lt;li&gt;Security weaknesses&lt;/li&gt;
&lt;li&gt;Key prefixing&lt;/li&gt;
&lt;li&gt;Borromean, Maxwell-Poelstra 2015&lt;/li&gt;
&lt;li&gt;Linkability and exculpability&lt;/li&gt;
&lt;li&gt;AND of \(\Sigma\)-protocols, DLEQ&lt;/li&gt;
&lt;li&gt;Liu-Wei-Wong 2004&lt;/li&gt;
&lt;li&gt;Security arguments for the LWW LSAG&lt;/li&gt;
&lt;li&gt;Back 2015 …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;h3&gt;Ring signatures&lt;/h3&gt;
&lt;h2&gt;Outline:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Basic goal of 1-of-\(N\) ring signatures&lt;/li&gt;
&lt;li&gt;Recap: the \(\Sigma\)-protocol&lt;/li&gt;
&lt;li&gt;OR of \(\Sigma\)-protocols, CDS 1994&lt;/li&gt;
&lt;li&gt;Abe-Ohkubo-Suzuki (AOS) 2002 (broken version)&lt;/li&gt;
&lt;li&gt;Security weaknesses&lt;/li&gt;
&lt;li&gt;Key prefixing&lt;/li&gt;
&lt;li&gt;Borromean, Maxwell-Poelstra 2015&lt;/li&gt;
&lt;li&gt;Linkability and exculpability&lt;/li&gt;
&lt;li&gt;AND of \(\Sigma\)-protocols, DLEQ&lt;/li&gt;
&lt;li&gt;Liu-Wei-Wong 2004&lt;/li&gt;
&lt;li&gt;Security arguments for the LWW LSAG&lt;/li&gt;
&lt;li&gt;Back 2015; compression, single-use&lt;/li&gt;
&lt;li&gt;Fujisaki-Suzuki 2007 and Cryptonote 2014&lt;/li&gt;
&lt;li&gt;Monero MLSAG&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Basic goal of 1-of-\(N\) ring signatures&lt;/h2&gt;
&lt;p&gt;The idea of a &lt;a href="https://en.wikipedia.org/wiki/Ring_signature"&gt;ring
signature&lt;/a&gt;
(the term itself is a bit sloppy in context, but let's stick with it
for now) is simple enough:&lt;/p&gt;
&lt;p&gt;An owner of a particular private key \(x\) signs a message \(m\) by
taking, usually without setup or interaction, a whole set of public
keys, one of which is his (\(P=xG\)), and forms a signature (exact
form unspecified) such that there is proof that &lt;strong&gt;at least one&lt;/strong&gt; of the
private keys is known to the signer, but which one was responsible for
the signature is not known by the verifier, and not calculatable.&lt;/p&gt;
&lt;p&gt;Obviously that's pretty vague but captures the central idea. We often
use the term "ring" because the construction must have some symmetry
over the entire set of \(n\) public keys, and a ring/circle represents
symmetry of an arbitrarily high order (limit of an \(n\)-gon). Less
abstractly it could be a good name because of some "loop"-ing aspect
of the algorithm that constructs the signature, as we'll see.&lt;/p&gt;
&lt;p&gt;What properties do we want then, in summation?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Unforgeability&lt;/li&gt;
&lt;li&gt;Signer ambiguity&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We may want additional properties for some ring signatures, as we'll
see.&lt;/p&gt;
&lt;p&gt;In the following sections I want to cover some of the key conceptual
steps to the kinds of ring signatures currently used in cryptocurrency
protocols; most notably Monero, but also several others; and also in the
Confidential Transactions construction (see: Borromean ring signatures,
briefly discussed here). I will also discuss security of such
constructions, in much less detail than the &lt;a href="https://web.archive.org/web/20200713230948/https://joinmarket.me/blog/blog/liars-cheats-scammers-and-the-schnorr-signature/"&gt;previous
blog&lt;/a&gt;
(on the security of Schnorr signatures), but showing how there are
several tricky issues to be dealt with, here.&lt;/p&gt;
&lt;h2&gt;Recap: the \(\Sigma\)-protocol&lt;/h2&gt;
&lt;p&gt;We consider a prover \(\mathbb{P}\) and a verifier \(\mathbb{V}\).&lt;/p&gt;
&lt;p&gt;A \(\Sigma\)-protocol is a three step game, in which the prover
convinces the verifier of something (it can be \(\mathbb{P}\)'s
knowledge of a secret, but it can also be something more complicated),
in zero knowledge. Readers interested in a much more detailed discussion
of the logic behind this and several applications of the idea can read
Sections 3 and 4 of my &lt;a href="https://github.com/AdamISZ/from0k2bp"&gt;From Zero (Knowledge) to
Bulletproofs&lt;/a&gt;
writeup, especially section 4.1.&lt;/p&gt;
&lt;p&gt;In brief, the three step game is:&lt;/p&gt;
&lt;p&gt;\(\mathbb{P} \rightarrow \mathbb{V}\): &lt;strong&gt;commitment&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;\(\mathbb{V} \rightarrow \mathbb{P}\): &lt;strong&gt;challenge&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;\(\mathbb{P} \rightarrow \mathbb{V}\): &lt;strong&gt;response&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A few minor notes on this: obviously the game is not literally over with
the response step; the verifier will examine the response to establish
whether it is valid or invalid.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;commitment&lt;/strong&gt; will usually in this document be written \(R\) and
will here always be a point on an elliptic curve, which the prover may
(or may not! in these protocols) know the corresponding scalar multiple
(private key or nonce) \(k\) such that \(R=kG\).&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;challenge&lt;/strong&gt; will usually be written \(e\) and will usually be
formed as the hash of some transcript of data; the subtleties around
exactly &lt;em&gt;what&lt;/em&gt; is hashed can be vitally important, as we'll see. (This
is in the "Fiat-Shamir transform" case; we discussed the pure
interactive challenge case a bit in the previous blog and many other
places!)&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;response&lt;/strong&gt; will usually be a single scalar which will usually be
denoted \(s\).&lt;/p&gt;
&lt;p&gt;We will be playing with this structure a lot: forging transcripts \(R,
e, s\); running multiple instances of a \(\Sigma\)-protocol in
parallel and performing logical operations on them. All of this will
play out &lt;em&gt;mostly&lt;/em&gt; in the form of a Schnorr signature; again, refer to
previous blog posts or elementary explanations (including those written
by me) for more on that.&lt;/p&gt;
&lt;h2&gt;OR of \(\Sigma\)-protocols, CDS 1994&lt;/h2&gt;
&lt;p&gt;Let's start with the OR of \(\Sigma\)-protocols. I &lt;em&gt;believe&lt;/em&gt; this
solution is due to &lt;a href="https://link.springer.com/content/pdf/10.1007%2F3-540-48658-5_19.pdf"&gt;Cramer, Damgård and Schoenmakers
'94&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(Historical note: the "believe" is because I've seen it cited to that
paper (which is famous for good reason, I guess); but in the paper they
actually attribute &lt;em&gt;this specific idea&lt;/em&gt; to "M. Ito, A. Saito, and T.
Nishizeki: Secret Sharing Scheme realizing any Access Structure, Proc.
Glob.Com. (1987)" ; unfortunately I can't find that on the 'net).&lt;/p&gt;
&lt;p&gt;It is also described, with a brief discussion of its security proof, in
&lt;a href="https://crypto.stanford.edu/~dabo/cryptobook/BonehShoup_0_4.pdf"&gt;Boneh-Shoup&lt;/a&gt;
Sec 19.7.2.&lt;/p&gt;
&lt;p&gt;This is not, as far as I know, used at all(?) nor that widely discussed,
but it is in some sense the most simple and logical way to get a 1 out
of \(N\) ring signature; use the XOR (\(\oplus\)) operation:&lt;/p&gt;
&lt;p&gt;We have in advance a set of public keys \(P_i\). We only know one
private key for index \(j\), \(x_j\).&lt;/p&gt;
&lt;p&gt;We'll now use a standard three move \(\Sigma\)-protocol to prove
knowledge of &lt;strong&gt;at least one key&lt;/strong&gt; without revealing which index is
\(j\).&lt;/p&gt;
&lt;p&gt;We're going to fake the non-\(j\)-index signatures in advance. Choose
\(s_i \stackrel{\$}{\leftarrow} \mathbb{Z}_N\ ,\ e_i
\stackrel{\$}{\leftarrow} \mathbb{Z}_N \quad \forall i \neq j\).&lt;/p&gt;
&lt;p&gt;Calculate \(R_i = s_iG - e_iP_i \quad \forall i \neq j\).&lt;/p&gt;
&lt;p&gt;For the real signing index, \(k_j \stackrel{\$}{\leftarrow}
\mathbb{Z}_N\ ,\quad R_j = k_jG\).&lt;/p&gt;
&lt;p&gt;We now have the full set of commitments: \((R_i \ \forall i)\)&lt;/p&gt;
&lt;p&gt;Now for the clever part. In an interactive \(\Sigma\)-protocol, we
would at this point receive a random challenge \(e \in
\mathbb{Z}_N\). For the Fiat Shamir transformed case,
noninteractively (as for  a signature), we use the constructed
\(R\)-values as input to a hash function, i.e. \(e = H(m||R_i
\ldots)\). We have already set the non-signing index \(e\)-values,
for the signing index we set \(e_j = e \oplus (\bigoplus_{i \ne
j}{e_i})\).&lt;/p&gt;
&lt;p&gt;This allows us to calculate \(s_j = k_j + e_j x_j\), and we now have
the full set of 'responses' for all the \(\Sigma\)-protocols:
\(s_i \ \forall i\). (but here we are using Fiat Shamir, so it's
not actually a response).&lt;/p&gt;
&lt;p&gt;By working this way we have ensured that the signature verifier can
verify that the logical XOR of the three \(e\)-values is equal to the
Fiat Shamir based hash-challenge, e.g. for the case of three
"signatures", we will have:&lt;/p&gt;
&lt;p&gt;\(e = e_1 \oplus e_2 \oplus e_3 \stackrel{?}{=}
H(m||R_0||R_1||...)\)&lt;/p&gt;
&lt;p&gt;where the verifier would calculate each \(R_i\) as \(s_iG -
e_iP_i\).&lt;/p&gt;
&lt;p&gt;The excellent feature of this of course is that it is perfectly hidden
which of the three indexes was genuine. But the bad news is that the
protocol as stated, used let's say as a signature scheme, requires
about twice as many field elements as members of the group of signers.
The verifier needs to be given \((s_1, \ldots s_n),(e_1 \ldots
e_n)\).&lt;/p&gt;
&lt;p&gt;Another excellent feature: this is not restricted to the Schnorr ID
protocol. It can work with another identity protocol, and even better,
it could work with a &lt;em&gt;mix&lt;/em&gt; of them; they only have to share the one
challenge \(e\).&lt;/p&gt;
&lt;h2&gt;Abe-Ohkubo-Suzuki (AOS) 2002 (broken version)&lt;/h2&gt;
&lt;p&gt;This is an excellent
&lt;a href="https://www.iacr.org/cryptodb/archive/2002/ASIACRYPT/50/50.pdf"&gt;paper&lt;/a&gt;
generally, but its stand-out contribution, in this context, is a &lt;strong&gt;more
compact&lt;/strong&gt; version of the 1 of n ring signature above. To clarify here,
both this and the previous are \(O(n)\) where \(n\) is the group
size, so "much more compact" is about the constant factor (scale not
scaling!); we reduce it from roughly 2 to roughly 1.&lt;/p&gt;
&lt;p&gt;"Broken version" - here I'll present a slightly simpler form than the
one in the paper, and then explain the serious problem with it - which I
hope will be productive. &lt;strong&gt;Please don't mistake this as meaning that
the AOS design was broken, it was never presented like this in the
paper!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Anyway, I think the best explanation for what's going on here
conceptually is due to A. Poelstra in the &lt;a href="https://github.com/Blockstream/borromean_paper"&gt;Borromean ring signatures
paper&lt;/a&gt;,
particularly Section 2 ; the reference to time travel may seem whimsical
but it gets to the heart of what's going on here; it's about having a
simulated form of causality with one way functions, and then violating
that.&lt;/p&gt;
&lt;p&gt;In short: creating an ordinary Schnorr sig without the key (i.e.
forging) is impossible because, working at the curve point level of the
equation (\(sG = R + H(m||R)P\)), you need to know the hash value
before you can calculate \(R\), but you need to know the value of
\(R\) before you can calculate the hash. So we see that two one way
functions are designed to conflict with one another; only by removing
one of them (going from curve points to scalar eqn: (\(s = k +
H(m||kG)x\)), can we now create a valid \(s, R, m\) set.&lt;/p&gt;
&lt;p&gt;To achieve that goal over a set of keys, we can make that "simulated
causality enforcement" be based on the same principle, but over a set
of equations instead of one. The idea is to make the commitment
\(H(m||R)\) use the \(R\) value from the "previous"
signer/key/equation, where "previous" is modulo \(N\), i.e. there is
a loop of dependencies (a ring, in fact).&lt;/p&gt;
&lt;p&gt;[Quick description:]{style="text-decoration: underline;"}&lt;/p&gt;
&lt;p&gt;Our goal is a list of \(N\) correctly verifying Schnorr signature
equations, with the tweak as mentioned that each hash-value refers to
the "previous" commitment. We will work with \(N=4\) and index from
zero for concreteness. Our goal is:&lt;/p&gt;
&lt;p&gt;\(s_0 G = R_0 + H(m||R_3)P_0\)&lt;/p&gt;
&lt;p&gt;\(s_1 G = R_1 + H(m||R_0)P_1\)&lt;/p&gt;
&lt;p&gt;\(s_2 G = R_2 + H(m||R_1)P_2\)&lt;/p&gt;
&lt;p&gt;\(s_3 G = R_3 + H(m||R_2)P_3\)&lt;/p&gt;
&lt;p&gt;Again for concreteness, we imagine knowing specifically the private key
\(x_2\) for index 2, only. We can successfully construct the above,
but only in a certain sequence:&lt;/p&gt;
&lt;p&gt;Choose \(k_2 \stackrel{\$}{\leftarrow} \mathbb{Z}_N,\ R_2 =
k_2G\), choose \(s_3 \stackrel{\$}{\leftarrow} \mathbb{Z}_N\).&lt;/p&gt;
&lt;p&gt;\(\Rightarrow R_3 = s_3 G - H(m||R_2)P_3\). Now choose \(s_0
\stackrel{\$}{\leftarrow} \mathbb{Z}_N\).&lt;/p&gt;
&lt;p&gt;\(\Rightarrow R_0 = s_0 G - H(m||R_3)P_0\). Now choose \(s_1
\stackrel{\$}{\leftarrow} \mathbb{Z}_N\).&lt;/p&gt;
&lt;p&gt;\(\Rightarrow R_1 = s_1 G - H(m||R_0)P_1\).&lt;/p&gt;
&lt;p&gt;Last, do not choose but &lt;strong&gt;calculate&lt;/strong&gt; \(s_2\): it must be \(s_2 = k_2
+ H(m||R_1)x_2\).&lt;/p&gt;
&lt;p&gt;After this set of steps, the set of data: \(e_0, s_0, s_1, s_2, s_3\)
can be verified without exposing which private key was known. Here is
the verification:&lt;/p&gt;
&lt;p&gt;Given \(e_0, s_0\), reconstruct \(R_0 = s_0G -e_0P_0\).&lt;/p&gt;
&lt;p&gt;\(\Rightarrow e_1 =H(m||R_0)\ ,\ R_1 = s_1 G - e_1P_1\)&lt;/p&gt;
&lt;p&gt;\(\Rightarrow e_2 =H(m||R_1)\ ,\ R_2 = s_2 G - e_2P_2\)&lt;/p&gt;
&lt;p&gt;\(\Rightarrow e_3 =H(m||R_2)\ ,\ R_3 = s_3 G - e_3P_3\)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Check&lt;/strong&gt;: \(e_0 \stackrel{?}{=} H(m||R_3)\).&lt;/p&gt;
&lt;h3&gt;Security weaknesses&lt;/h3&gt;
&lt;p&gt;The description above can't be described as secure.&lt;/p&gt;
&lt;p&gt;To give a hint as to what I mean: is there something &lt;strong&gt;not completely
fixed&lt;/strong&gt; in the above construction? Maybe an issue that's not even
specific to the "ring" construction, but even for any one of the
signature equations?&lt;/p&gt;
&lt;p&gt;....&lt;/p&gt;
&lt;p&gt;The answer is the keys, \(P_i\). We can in the most general case
consider three scenarios, although there may be some gray areas between
them:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Key(s) fixed in advance: \(P_1 \ldots P_N\) are all specified
    before doing anything, and not allowed to change by the verifier.
    Every signature must be on that set of keys.&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;set&lt;/em&gt; &lt;em&gt;of possible keys&lt;/em&gt; is fixed in advance exactly as
    described above, but the &lt;em&gt;set of keys used in the ring&lt;/em&gt; is chosen by
    the signer, dynamically, in signing oracle queries or forgery
    attempts.&lt;/li&gt;
&lt;li&gt;Even the set of possible keys is dynamic. That is to say, any valid
    curve point (for EC case) is a valid potential key in (ring)
    signature.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is not a full taxonomy of possible attack scenarios, either. Not
only must we consider the difference between EUF-CMA and SUF-CMA as was
discussed in the previous blog (a reminder: with SUF, a forger should
not be able to even create a second signature on the same message -
ECDSA doesn't have this in naive form), but much more: we must also
consider which of the above three key settings applies.&lt;/p&gt;
&lt;p&gt;Even outside of ring signature settings, just considering a large scale
deployment of a signature scheme across millions or billions of keys,
could mean that the difference between these cases really matters. In
&lt;a href="https://eprint.iacr.org/2015/996"&gt;this&lt;/a&gt;
paper by Dan Bernstein the term MU-UF-CMA is used to refer to the
"multi-user" setting for this, where only single-key signatures are
used but one must consider whether having billions of other keys and
signing oracles for them might impact the security of &lt;strong&gt;any one&lt;/strong&gt; key
(notice the huge difference between "I want to forge on \(P\)" and
"I want to forge on any existing key" is, in this scenario).&lt;/p&gt;
&lt;p&gt;So enough about settings, what exactly constitutes a security problem
with the above version of the AOS ring sig?&lt;/p&gt;
&lt;p&gt;Consider any one element in the ring like:&lt;/p&gt;
&lt;p&gt;\(s_0 = R_0 + H(m||R_3)P_0\)&lt;/p&gt;
&lt;p&gt;where, for concreteness, I choose \(n=4\) and look at the first of 4
signature equations. Because of Schnorr's linearity (see &lt;a href="https://web.archive.org/web/20200713230948/https://joinmarket.me/blog/blog/flipping-the-scriptless-script-on-schnorr/"&gt;this earlier
blog
post&lt;/a&gt;
for some elucidations on the &lt;em&gt;advantage&lt;/em&gt; of this linearity, although it
was also noted there that it had concomitant dangers (worse,
actually!)), there are two obvious ways we could tweak this equation:&lt;/p&gt;
&lt;p&gt;(1) Tweaked \(s\) values on fixed message and tweaked keys:&lt;/p&gt;
&lt;p&gt;Choose \(\alpha \in \mathbb{Z}_N\) and set \(s' = s_0
+\alpha\). We will not alter \(R=kG\), but we alter \(P_0
\rightarrow P_0 + e_0\^{-1}\alpha G\). This makes the verification
still work &lt;strong&gt;without altering the fixing of the nonce in the hash value
\(e_0\):&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;\(s_0 G + \alpha G = R_0 + e_0 P_0 + \alpha G = R_0 + e_0\left(P_0 +
e_0\^{-1}\alpha G\right)\)&lt;/p&gt;
&lt;p&gt;So it's really not clear how bad this failing is; it's &lt;em&gt;kinda&lt;/em&gt; a
failure of strong unforgeability, but that notion doesn't precisely
capture it: we created a new, valid signature against a
[new]{style="text-decoration: underline;"} key, but with two severe
limitations: we weren't able to alter the message, and also, we
weren't able to &lt;em&gt;choose&lt;/em&gt; the new key \(P'\). That last is slightly
unobvious, but crucial : if I have a pre-prepared \(P\^{*}\), I
cannot choose \(\alpha\) to get \(P' = P\^{*}\) as that would
require a discrete logarithm break.&lt;/p&gt;
&lt;p&gt;A final statement, hopefully obvious: the above can apply to any and all
of the elements of the ring, so the forgery could consist of an entirely
different and random set of keys, not related to the starting set; but
the message would be the same, as would the \(R\) values.&lt;/p&gt;
&lt;p&gt;(2) Completely different messages on tweaked keys, with the same
signature&lt;/p&gt;
&lt;p&gt;This one is almost certainly more important. Algebraically, we here
allow alterations to the \(e\) values, using multiplication rather
than addition:&lt;/p&gt;
&lt;p&gt;Given the same starting \(s_0\) as in (1), we take a chosen new
message \(m\^{*}\) and calculate the new \(e\^{*} =
H(m\^{*}||R_3)\). If we likewise tweak the public key we get that
\(s_0, R_0\) is a valid signature on the new message, with the tweaked
key:&lt;/p&gt;
&lt;p&gt;\(s_0 G = R_0 + e_0\^{*}\left(\frac{e_0}{e_0\^{*}} P_0\right)\)&lt;/p&gt;
&lt;p&gt;We can see here that this produces a forgery with the same signature
values (but different hash values) on the new keys.&lt;/p&gt;
&lt;p&gt;Most definitions of security against forgery require the attacker to
create a signature on a not-previously-queried message - so this &lt;em&gt;is&lt;/em&gt; a
successful attack, by most measures.&lt;/p&gt;
&lt;p&gt;However it does share the same limitation with (1) mentioned above -
that you cannot "control" the keys on which you get a signature,
unless you know a relative discrete log between one of the existing keys
and your new key, which implies you knew the secret key of the first (in
which case all this is pointless; whenever you have a private key, there
is no forgery on it).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;All of this should make very clear the reason why the real AOS (see
Section 5.1 of the paper) discrete-log ring signature fixes the entire
set of keys inside the hash, i.e. \(e_i = H(m || R_{(i-1)\%n}||
P_0 \ldots P_{n-1})\).&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;Key Prefixing&lt;/h3&gt;
&lt;p&gt;The method in the previous bolded sentence is sometimes called
"key-prefixing". One way of looking at it: the Fiat-Shamir transform
that takes the Identity Protocol into a signature scheme, should hash
the conversation transcript between the prover and verifier, previous to
the challenge step; by including the public keys in this hash, we are
treating the keyset as part of the conversation transcript, rather than
something ex-protocol-run.&lt;/p&gt;
&lt;p&gt;Also, the discussion above (both cases (1) and (2)) show clearly that
the same weakness exists for a single (\(n=1\)) key case.&lt;/p&gt;
&lt;p&gt;[And yet, for the single key case, it was not a done deal historically -
this caused real world arguments!]{style="text-decoration: underline;"}.
After all, there are many use cases where the key &lt;em&gt;is&lt;/em&gt; a given
ex-protocol-run, plus there may be some practical disadvantage to doing
the key-prefixing.&lt;/p&gt;
&lt;p&gt;In
&lt;a href="https://rd.springer.com/chapter/10.1007%2F978-3-662-53008-5_2"&gt;this&lt;/a&gt;
paper from CRYPTO-2016, the controversy arising out of this is
elucidated, showing that these theoretical concerns had very substantial
impact on arguably the largest real world crypto usage (TLS):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;"Key-prefixing comes with the disadvantage that the entire public-key
has to\
be available at the time of signing. Specifically, in a CFRG message
from Sep-\
tember 2015 Hamburg [32] argues "having to hold the public key along
with\
the private key can be annoying" and "can matter for constrained
devices".\
Independent of efficiency, we believe that a cryptographic protocol
should be\
as light as possible and prefixing (just as any other component)
should only\
be included if its presence is justified. Naturally, in light of the
GMLS proof,\
Hamburg [32] and Struik [44] (among others) recommended against
key prefixing\
for Schnorr. Shortly after, Bernstein [10] identifies the error in
the GMLS theo-\
rem and posts a tight security proof for the key-prefixed variant of
Schnorr signa-\
tures. In what happens next, the participant of the CFRG mailing list
switched\
their minds and mutually agree that key-prefixing should be preferred,
despite of\
its previously discussed disadvantages. Specifically, Brown writes
about Schnorr\
signatures that "this justifies a MUST for inclusion of the public key
in the mes-\
sage of the classic signature" [16]. As a consequence, key-prefixing
is contained in\
the current draft for EdDSA [33]..."&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;Technical note: the "GMLS proof" mentioned in the above is the proof
given in
&lt;a href="https://www.researchgate.net/publication/256720499_Public_key_signatures_in_the_multi-user_setting"&gt;this&lt;/a&gt;
paper, that was intended to reduce the security of the multi-user
setting to that of the single-user setting, and that Dan Bernstein's
&lt;a href="https://eprint.iacr.org/2015/996"&gt;paper&lt;/a&gt;
previously mentioned proved to be invalid.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;What's the TLDR? Fix the keys in any group/ring/multisignature. And
even that may not be enough, see
&lt;a href="https://eprint.iacr.org/2018/068"&gt;MuSig&lt;/a&gt;
for details of why it really isn't, in the scenario of Bitcoin
aggregated multisig.&lt;/p&gt;
&lt;h2&gt;Borromean, Maxwell-Poelstra 2015&lt;/h2&gt;
&lt;p&gt;I covered this extensively (including description of AOS as above) in my
&lt;a href="https://github.com/AdamISZ/ConfidentialTransactionsDoc/"&gt;CT
writeup&lt;/a&gt;
section 3.2&lt;/p&gt;
&lt;p&gt;The idea of the construction as outlined in &lt;a href="https://github.com/Blockstream/borromean_paper"&gt;the paper by Maxwell,
Poelstra&lt;/a&gt;
is to increase the space-efficiency of the published proof even more. By
having several ring signatures joined at a single index we get a
reduction in the number of \(e\) values we publish. This is basically
the same idea as the "AND of \(\Sigma\)-protocols" discussed a
little later in this document (although here we will only be using it
for achieving a specific goal, "Linkability", see more on this next).&lt;/p&gt;
&lt;p&gt;For the real world context - Borromean ring signatures are used in
certain implementations of Confidential Transactions (e.g. Liquid by
Blockstream) today, and were previously used also in Monero for the same
goal of CT. They are a radically different use-case of ring signatures
to the one mostly described in the below; instead of using a ring
signature to hide the identity of a signer, they are used to hide which
exponent contains values in the encoding of a value committed to in a
Pedersen commitment. This allows arithmetic to be done on the
Pedersen-committed amount without worrying about overflow into negative
values modulo \(N\).&lt;/p&gt;
&lt;h2&gt;Linkability and Exculpability&lt;/h2&gt;
&lt;p&gt;In this section we'll briefly describe certain key features that turn
out to be useful in some real-world applications of a ring signature,
before in the following sections laying out how these features are, or
are not, achieved.&lt;/p&gt;
&lt;h3&gt;Linkability (and spontaneity)&lt;/h3&gt;
&lt;p&gt;At first glance, the idea "linkability" with a ring signature seems to
be a contradiction. Since we are trying to achieve signer
ambiguity/anonymity, we don't really want any "linking" being done.
But the idea is rather clever, and proves to be very interesting for
digital cash.&lt;/p&gt;
&lt;p&gt;In a &lt;strong&gt;linkable&lt;/strong&gt; ring signature, a participant with key \(P \in L\)
(i.e. \(L\) is a particular set of public keys), should be able to
produce one ring signature on a given message, but should not be able to
do so again without the two ring signatures being linked. Thus,
functionally, each participant can only make such a signature once
(note: they can still retain anonymity if double-signing).&lt;/p&gt;
&lt;p&gt;This restriction-to-one-signature-while-keeping-anonymity is easily seen
to be valuable in cases like electronic voting or digital cash, as well
as the oft-cited example explained in the next paragraph.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;spontaneity&lt;/strong&gt; property should be a lot more obvious. Consider the
example of a whistleblower. We would want individuals in some large
group (e.g. government bureaucrats) to attest to a statement, while only
revealing group membership and not individual identity. Clearly this is
not workable if it requires cooperation of other members of the group
(even in any setup phase), so it's necessary that the individual can
create the ring signature "spontaneously", knowing only the public key
of other participants.&lt;/p&gt;
&lt;p&gt;The paper uses the abbreviation LSAG for this type of signature:
"Linkable Spontaneous Anonymous Group" signature.&lt;/p&gt;
&lt;p&gt;Note that the previous two constructions (CDS, AOS) can also have this
spontaneity property; but not the linkability property.&lt;/p&gt;
&lt;h3&gt;Culpability, Exculpability and Claimability&lt;/h3&gt;
&lt;p&gt;A ring signature can be described as exculpable if, even given knowledge
of the signing private key, an adversary cannot deduce that that signing
key was the one used to create the ring signature.&lt;/p&gt;
&lt;p&gt;Notice that such a property may be immensely important in a range of
scenarios where a ring sig is useful - e.g. for a whistleblower whose
cryptographic keys were stolen or extracted by force, he could still
plausibly deny being the origin of a leak.&lt;/p&gt;
&lt;p&gt;The reader can easily verify that the AOS construction, for example, has
this exculpability. The fact that a particular key is released e.g.
\(x_2\) in our concrete example, does not allow inference of it having
been used to create that signature. Any other key could have created the
signature, using the same signing algorithm.&lt;/p&gt;
&lt;p&gt;The LWW LSAG, which we'll describe shortly, is on the other hand
&lt;strong&gt;culpable&lt;/strong&gt;, i.e. the opposite - because the key image can be verified
to be tied to one particular key.&lt;/p&gt;
&lt;p&gt;It's easy to see that the two properties &lt;strong&gt;exculpability&lt;/strong&gt; and
&lt;strong&gt;linkability&lt;/strong&gt; are somewhat in conflict, although I'm not aware of a
theorem that &lt;em&gt;absolutely requires&lt;/em&gt; linkability to somehow tag one key in
case it is leaked.&lt;/p&gt;
&lt;p&gt;Lastly, I'll mention &lt;strong&gt;claimability&lt;/strong&gt;, which is briefly described also
in the LWW paper (see below). It may be possible for the owner of a key
to independently/voluntarily prove that they were the source of a given
ring signature, which doesn't logically require culpability.
Claimability is generally easy to achieve with some proof of knowledge
technique.&lt;/p&gt;
&lt;h2&gt;AND of \(\Sigma\)-protocols, DLEQ&lt;/h2&gt;
&lt;p&gt;The thoughtful reader probably won't have much trouble in imagining
what it would mean to do the logical AND of 2 \(\Sigma\)-protocols.&lt;/p&gt;
&lt;p&gt;"AND" here just means you need to prove to the Verifier that you know
both secrets / both conditions are true. So this only requires that you
can answer both challenges (second step) with correct responses. Using
the standard notation, that means generating two transcripts:&lt;/p&gt;
&lt;p&gt;\((R_1, e, s_1) \quad (R_2, e, s_2)\)&lt;/p&gt;
&lt;p&gt;i.e. the same \(e\)-value is given to both protocol runs after
receiving the initial commitments from each. Fiat-Shamir-ising this
protocol will work the same as the usual logic; if considering a
signature scheme, we'll be hashing something like
\(H(m||R_1||R_2||P_1||P_2)\), if we include, as we have learnt
to, key-prefixing.&lt;/p&gt;
&lt;p&gt;As we already mentioned, the Borromean ring signature design uses this
idea to compactify a set of ring signatures, since only one
\(e\)-value is being published, rather than \(M\) for \(M\) ring
signatures.&lt;/p&gt;
&lt;p&gt;This much is not super-interesting; but we can tighten this up a bit and
only use &lt;strong&gt;one&lt;/strong&gt; commitment and response in a special case:&lt;/p&gt;
&lt;h3&gt;Proof of Discrete Log Equivalence (DLEQ, PoDLE)&lt;/h3&gt;
&lt;p&gt;See one of the first posts on this
&lt;a href="https://web.archive.org/web/20200713230948/https://joinmarket.me/blog/blog/poodle"&gt;blog&lt;/a&gt;
for a description of this technique; here we're giving a slightly
deeper look at the meaning.&lt;/p&gt;
&lt;p&gt;If you are proving not only knowledge of a secret \(x\), but also that
two curve points have the same discrete log \(x\) w.r.t. different
bases \(G\) and \(J\) (whose relative discrete log must not be
known; see earlier blog post etc.), you can condense the above AND by
reusing the commitment and challenge for the two bases:&lt;/p&gt;
&lt;p&gt;\(\mathbb{P} \rightarrow \mathbb{V}\): \(R_1= kG,R_2=kJ\)&lt;/p&gt;
&lt;p&gt;\(\mathbb{V} \rightarrow \mathbb{P}\): \(e =
H(m||R_1||R_2||P_1||P_2)\)&lt;/p&gt;
&lt;p&gt;\(\mathbb{P} \rightarrow \mathbb{V}\): \(s\),  (in secret:
\(=k+ex\))&lt;/p&gt;
&lt;p&gt;Now, if the prover acted honestly, his construction of \(s\) will
correctly pass verification &lt;strong&gt;twice&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;\(sG \stackrel{?}{=}R_1 +e P_1 \quad sJ \stackrel{?}{=} R_2 +
eP_2\)&lt;/p&gt;
&lt;p&gt;... and notice that it would be impossible to make that work for
different \(x\)-values on the two bases \(G\) and \(J\) because
you would need to find \(k_1, k_2 \in \mathbb{Z}_N, x_1, x_2 \in
\mathbb{Z}_N\) such that, &lt;strong&gt;without knowing \(e\) in advance,&lt;/strong&gt;
\(s = k_1 + ex_1 =k_2 + ex_2\), which is clearly impossible.&lt;/p&gt;
&lt;p&gt;Proof of soundness is easy to see using the standard rewinding technique
(see e.g. previous blog post amongst many other places); after the two
upfront commitments are fixed and the \(e\)-values are "forked", we
will get two \(s\) values as usual and extract \(x\).&lt;/p&gt;
&lt;h2&gt;Liu-Wei-Wong 2004 LSAG&lt;/h2&gt;
&lt;p&gt;Shortly after the AOS paper, Liu, Wei and Wong published a
&lt;a href="https://www.researchgate.net/publication/220798466_Linkable_Spontaneous_Anonymous_Group_Signature_for_Ad_Hoc_Groups_Extended_Abstract"&gt;paper&lt;/a&gt;
outlining how the same basic idea could be extended to a slightly more
complex context of requiring &lt;strong&gt;linkability&lt;/strong&gt;, as earlier mentioned. It
uses a combination of the above: DLEQ via AND of
\(\Sigma\)-protocols, and OR of \(\Sigma\)-protocols for the ring
signature hiding effect. Detailed algorithm with commentary follows.&lt;/p&gt;
&lt;h3&gt;Liu-Wei-Wong's LSAG algorithm&lt;/h3&gt;
&lt;p&gt;We start with a keyset \(L = \{P_0 \ldots P_{n-1}\}\) chosen by
the signer, whose index will be \(\pi\) (note the ambiguities about
"what is the set of valid keys?" as was discussed under "Key
Prefixing"). We then form a special new kind of curve point that we'll
name from now on as the &lt;strong&gt;key image&lt;/strong&gt; (for reasons that'll become
clear):&lt;/p&gt;
&lt;p&gt;\(I =x_{\pi} \mathbb{H}(L)\)&lt;/p&gt;
&lt;p&gt;Here \(\mathbb{H}\) is a hash function whose output space is points
on the curve, rather than scalar numbers. (&lt;em&gt;The mechanical operation for
doing this is sometimes described as "coerce to point"; for example,
take the 256 bit number output by SHA256 and interpret it as an
\(x-\)coordinate on secp256k1, find the "next" valid point
\(x,y\), incrementing \(x\) if necessary, or whatever; just has to
be deterministic&lt;/em&gt;). \(\mathbb{H}(L)\) is therefore going to play the
same role as \(J\) in the previous section, and we assume
intractability of relative discrete log due to the hashing.&lt;/p&gt;
&lt;h3&gt;Signing LWW LSAG&lt;/h3&gt;
&lt;p&gt;The following steps are very similar "in spirit" to AOS; we still
"extend the causality loop" (bastardising Poelstra's description)
over the whole set of signatures instead of just one, but this time we
also "lift" the loop onto a base of \(\mathbb{H}(L)\) and replicate
the signatures there, too:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Set \(k_{\pi} \stackrel{\$}{\leftarrow} \mathbb{Z}_N\)&lt;/li&gt;
&lt;li&gt;Form the hash-challenge at the next index: \(e_{\pi+1} =
    H(m||L||k_{\pi}G||k_{\pi}\mathbb{H}(L)||I)\)&lt;/li&gt;
&lt;li&gt;Note to the above: \(k_{\pi}G\) was previously called
    \(R_{\pi}\) in AOS; we are trying to preserve here, the same
    notation where possible; and of course it's the \(R\) value, not
    the \(k\)-value that will be known/calculated by the verifier. The
    same applies to the "lifted" nonce-point which follows it in the
    concatenation. With respect to the key image, note that it &lt;em&gt;will&lt;/em&gt; be
    published and known to the verifier; but he won't know which index
    it corresponds to.&lt;/li&gt;
&lt;li&gt;Pick \(s_{\pi+1} \stackrel{\$}{\leftarrow} \mathbb{Z}_N\);
    then we do as in AOS, but duplicated; we set:&lt;/li&gt;
&lt;li&gt;\(R_{\pi+1} = s_{\pi+1}G - e_{\pi+1}P_{\pi+1}\) and
    \(R\^{*}_{\pi+1} = s_{\pi+1}\mathbb{H}(L) - e_{\pi+1}I\)&lt;/li&gt;
&lt;li&gt;I realise the last line is pretty dense, so let's clarify: the
    first half is exactly as for AOS; calculate \(R\) given the random
    \(s\) and the just-calculated hash value \(e\). The &lt;em&gt;second&lt;/em&gt;
    half is &lt;strong&gt;the same thing with the base point \(G\) replaced with
    \(\mathbb{H}(L)\), and the pubkey replaced with \(I\) at every
    index&lt;/strong&gt;. We used a shorthand \(R\^{*}\) to mean
    \(k_{\pi+1}\mathbb{H}(L)\), because of course we don't
    actually &lt;em&gt;know&lt;/em&gt; the value \(k_{\pi+1}\).&lt;/li&gt;
&lt;li&gt;Calculate the next hash-challenge as \(e_{pi+2} =
    H(m||L||R_{\pi+1}||R\^{*}_{\pi+1}||I)\)&lt;/li&gt;
&lt;li&gt;Etc...&lt;/li&gt;
&lt;li&gt;As with AOS, we can now forge all the remaining indices, wrapping
    around the loop, by repeating the above operation, generating a new
    random \(s\) at each step, until we get back to the signing index
    \(\pi\), when we must calculate \(s_{\pi}\) as: \(s_{\pi}
    = k_{\pi} + e_{\pi}x_{\pi}\).&lt;/li&gt;
&lt;li&gt;Signature is published as \(\sigma_{L}(m) = (s_0 \ldots
    s_{n-1}, e_0, I)\). (As before, if the keyset \(L\) is not
    specified in advance, it will have to be published for the
    verifier).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So what we're doing here is OR(DLEQ(0), DLEQ(1),.... DLEQ(n-1)). And
as observed, each DLEQ is actually an AND: "AND(I know x for P, x for P
is same as x for P2)". Hence this represents a clever combination of
AND- and OR- of \(\Sigma\)-protocols.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;On a personal note, when I first saw something of this type (I think it
was Cryptonote, see below), I found it quite bewildering, and I'm sure
I'm not alone! But what partially saved me is having already studied
PoDLE/DLEQ as well as AOS ring sigs, so I could intuit that something
combining the two ideas was going on. I hope the previous painstaking
introductions make it all a lot clearer!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Note the key similarities and difference(s) in the published signature,
to the AOS case: you still only need to publish one hash \(e_0\) since
the others are determined by it, but you &lt;strong&gt;must&lt;/strong&gt; publish also the key
image \(I\); if another LWW LSAG is published using the same private
key, it will perforce have the same key image, and be recognized as
having come from the same key [without revealing which
key]{style="text-decoration: underline;"}.&lt;/p&gt;
&lt;p&gt;The protocol using the LSAG can thus reject a "double-sign", if
desired.&lt;/p&gt;
&lt;p&gt;Let's sanity check that we understand the verification algorithm, since
it is slightly different than AOS:&lt;/p&gt;
&lt;h3&gt;Verifying LWW LSAG&lt;/h3&gt;
&lt;p&gt;Start with the given keyset \(L\), the message \(m\) and the
signature \((s_0 \ldots s_{n-1}, e_0, I)\)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Construct \(e_{1} = H(m||L||R_{0}||R\^{*}_{0}||I)\)
    using \(R_0 = s_0G - e_0 P_0\) and \(R\^{*}_{0} = s_0
    \mathbb{H}(L) - e_0 I \)&lt;/li&gt;
&lt;li&gt;Repeat at each index using the new \(e_j\) until \(e_0\) is
    calculated at the last step and verify it matches: \(e_0
    \stackrel{?}{=} H(m||L||R_{n-1}||R\^{*}_{n-1}||I)\).
    Accept if so, reject if not.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(with the additional point mentioned: the protocol using the sig scheme
may also reject this as valid if \(I\) has already been used; this
additional protocol step is usually described as "LINK" in the
literature).&lt;/p&gt;
&lt;h3&gt;A brief note on the key image&lt;/h3&gt;
&lt;p&gt;Make sure you get the difference between this \(\mathbb{H}(L)\) and
the previous \(J\) as per the general DLEQ. In the latter case we can
(and should) choose an arbitrary globally-agreed NUMS point, for example
hashing the standard curve base point \(G\) (with the
"coerce-to-point" technique mentioned). In this case, we have chosen
something that both signer and verifier agree on, as part of the
&lt;strong&gt;setting&lt;/strong&gt; of this particular run of the protocol - it's
deterministically tied to the keyset \(L\). The key image\(I\) is
analogous to \(P_2\) in my PoDLE blog post; it's the signer's
"hidden", one-time key.&lt;/p&gt;
&lt;p&gt;This changes in the next construction, Back 2015. But first, a few words
on security.&lt;/p&gt;
&lt;h2&gt;Security arguments for the LWW LSAG&lt;/h2&gt;
&lt;p&gt;The general approach to proving &lt;strong&gt;unforgeability&lt;/strong&gt; of this ring
signature is the same as that for the basic Schnorr signature as
described in the previous blog post.&lt;/p&gt;
&lt;p&gt;A wrapper around an attacker \(\mathbb{A}\) who we posit to have the
ability to construct a forgery without knowing any private key
\(x_i\), will, as before, have to guess which random oracle query
corresponds to the forgery, and will want to provide two different
"patched" answers to the RO query at that point. As before, there will
be some reduced probability of success due to having to make this kind
of guess, and so the reduction will be even less tight than before.&lt;/p&gt;
&lt;p&gt;Also as before, in the EUF-CMA model, we must allow for an arbitrary
number of signing oracle as well as RO queries, which complicates the
statistical analysis considerably, but the basic principles remain the
same. If at some point forgery is successfully achieved twice at the
same index, we will have something like:&lt;/p&gt;
&lt;p&gt;\(x_{\pi} =
\frac{s\^{*}_{\pi}-s_{\pi}}{e\^{*}_{\pi}-e_{\pi}}\)&lt;/p&gt;
&lt;p&gt;where the * superscripts indicate the second run, and the
\(e\)-values being the patched RO responses.&lt;/p&gt;
&lt;p&gt;And as usual, with appropriate statistical arguments, one can generate a
reduction such that forgery ability with a certain probability \(p\)
implies thus ability to solve ECDLP with a related probability
\(p'\).&lt;/p&gt;
&lt;p&gt;For proving &lt;strong&gt;signer ambiguity&lt;/strong&gt; - for simplicity, we break this into
two parts. If &lt;em&gt;all&lt;/em&gt; of the private keys are known to the attacker (e.g.
by subpoena), then this property completely fails. This is what we
called &lt;strong&gt;culpability&lt;/strong&gt;. It's easy to see why - we have the key image as
part of the signature, and that is deterministically reproducible given
the private key. If &lt;em&gt;none&lt;/em&gt; of the private keys are known to the
attacker, the problem is reduced to the &lt;strong&gt;solution of the &lt;a href="https://en.wikipedia.org/wiki/Decisional_Diffie%E2%80%93Hellman_assumption"&gt;Decisional
Diffie Hellman
Problem&lt;/a&gt;&lt;/strong&gt;,
which is considered computationally hard. The reduction is quite
complicated, but as in a standard zero knowledgeness proof, the idea is
that a Simulator can generate a transcript that's statistically
indistinguishable from a genuine transcript.&lt;/p&gt;
&lt;p&gt;For proving &lt;strong&gt;linkability &lt;/strong&gt; - in the LWW paper an argument is made that
this reduces to ECDLP in more or less the same was as for the
unforgeability argument, using two pairs of transcripts for two
different signatures which are posited to be based on the same private
key but having different key images. Examination of the two pairs of
transcripts allows one to deduce that the private key in the two cases
are the same, else ECDLP is broken.&lt;/p&gt;
&lt;p&gt;Notice that these security arguments are [much more complicated than for
the single Schnorr signature case]{style="text-decoration: underline;"}
and perhaps for two distinct reasons: one, because the ring signature is
a more complex algebraic construction, with more degrees of freedom, but
also, because we are asking for a significantly richer set of properties
to hold. In particular notice that even for unforgeability, the EUF-CMA
description is not good enough (we've already discussed this a bit); we
need to consider what happens when creating multiple signatures on
different keysets and how they overlap. Signer anonymity/ambiguity is
especially difficult for LWW and its postdecessors (see below), because
by design it has been weakened (culpability).&lt;/p&gt;
&lt;h2&gt;Back 2015; compression, single-use&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;This is a good place to note that the constructions starting with LWW
are described in some detail in the useful document
&lt;a href="https://ww.getmonero.org/library/Zero-to-Monero-1-0-0.pdf"&gt;Zero-To-Monero&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Adam Back
&lt;a href="https://bitcointalk.org/index.php?topic=972541.msg10619684#msg10619684"&gt;posted&lt;/a&gt;
in 2015 on bitcointalk about a potential space saving over the
cryptonote ring signature, based on using AOS and tweaking it to include
a key image.&lt;/p&gt;
&lt;p&gt;As was noted above, it's a space saving of asymptotically about 50% to
use a scheme like AOS that only requires publication of one hash
challenge as opposed to one for each index (like the CDS for example).&lt;/p&gt;
&lt;p&gt;He then followed up noting that a very similar algorithm had already
been published, namely the LWW we've just described in the above, and
moreover it was published three years before Fujisaki-Suzuki that was
the basis of cryptonote (see below). So it was &lt;em&gt;somewhat&lt;/em&gt; of an
independent re-discovery, but there is a significant tweak. I'll
outline the algorithm below; it'll look very similar to LWW LSAG, but
there's a difference.&lt;/p&gt;
&lt;h3&gt;Signing Back-LSAG&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Define key image \(I =x_{\pi}\mathbb{H}(P_{\pi})\);&lt;/li&gt;
&lt;li&gt;Set \(k_{\pi} \stackrel{\$}{\leftarrow} \mathbb{Z}_N\)&lt;/li&gt;
&lt;li&gt;Form the hash-challenge at the next index: \(e_{\pi+1} =
    H(m||k_{\pi}G||k_{\pi}\mathbb{H}(P_{\pi}))\)&lt;/li&gt;
&lt;li&gt;Pick \(s_{\pi+1} \stackrel{\$}{\leftarrow} \mathbb{Z}_N\);
    then:&lt;/li&gt;
&lt;li&gt;\(R_{\pi+1} = s_{\pi+1}G - e_{\pi+1}P_{\pi+1}\) and
    \(R\^{*}_{\pi+1} = s_{\pi+1}\mathbb{H}(P_{\pi+1}) -
    e_{\pi+1}I\)&lt;/li&gt;
&lt;li&gt;Calculate the next hash-challenge as \(e_{pi+2} =
    H(m||R_{\pi+1}||R\^{*}_{\pi+1})\)&lt;/li&gt;
&lt;li&gt;Etc...&lt;/li&gt;
&lt;li&gt;As with AOS and LWW, we can now forge all the remaining indices,
    wrapping around the loop, by repeating the above operation,
    generating a new random \(s\) at each step, until we get back to
    the signing index \(\pi\), when we must calculate \(s_{\pi}\)
    as: \(s_{\pi} = k_{\pi} + e_{\pi}x_{\pi}\).&lt;/li&gt;
&lt;li&gt;Signature is published as \(\sigma_{L}(m) = (s_0 \ldots
    s_{n-1}, e_0, I)\), as in LWW (\(L\) being the set of \(P\)s).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Verification for this is near-identical as for LWW, so is left as an
exercise for the reader.&lt;/p&gt;
&lt;h3&gt;What's the difference, and what's the purpose?&lt;/h3&gt;
&lt;p&gt;The tweak - which is very similar to Cryptonote (makes sense as it was
an attempt to improve that) - is basically this: by making each of the
signatures in the shifted base point version symmetrical (example:
\(s_2 \mathbb{H}(P_2) = k_2 \mathbb{H}(P_2) + e_2 I\)), it means
that a key image will be valid &lt;em&gt;independent of the set of public keys,
\(L\).&lt;/em&gt; This is crucial in a cryptocurrency application - we need the
key image to be a unique double spend signifier across many different
ring signatures with different keysets - the keys are ephemeral and
change between transactions.&lt;/p&gt;
&lt;p&gt;So it's a blend of the LWW LSAG, which has the advantage of space
compaction for the same reason as AOS - only one hash must be published,
the others can be deduced from the ring structure - with the
F-S-2007/Cryptonote design, which fixes the key image to the key and not
just the specific ring.&lt;/p&gt;
&lt;p&gt;However I have to here leave open whether the security arguments of LWW
carry across to this case. I note that the original description did
&lt;em&gt;not&lt;/em&gt; include the keyset in the hash challenge (notice absence of
\(L\)); but see the note on MLSAG below.&lt;/p&gt;
&lt;h2&gt;Fujisaki-Suzuki 2007 and Cryptonote&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://cryptonote.org/whitepaper.pdf"&gt;Cryptonote&lt;/a&gt;
was adapted from a paper of &lt;a href="https://eprint.iacr.org/2006/389.pdf"&gt;Fujisaki and
Suzuki&lt;/a&gt;
describing an alternate version of a linkable (here "traceable") ring
signature, in 2007. We won't dwell on these constructions here (except
inasmuch as we referred to them above), as they provide the same
linkability function as the above LSAG, but are less compact. Instead,
in the final section, I'll describe how Monero has applied LWW LSAG and
the Back LSAG to their specific requirements.&lt;/p&gt;
&lt;h2&gt;Monero MLSAG&lt;/h2&gt;
&lt;p&gt;For anyone paying close attention all the way through, there will be
nothing surprising here!&lt;/p&gt;
&lt;p&gt;For a cryptocurrency, we build transactions consisting of multiple
inputs. Each input in Monero's case uses a ring signature, rather than
a single signature, to authenticate the transfer, referring back to
multiple pubkeys possessing coins as outputs of earlier transactions.&lt;/p&gt;
&lt;p&gt;So here we need &lt;strong&gt;one ring signature per input&lt;/strong&gt;. Moreover, per normal
transaction logic, we obviously need &lt;em&gt;all&lt;/em&gt; of those ring signatures to
successfully verify. So this is another case for the "AND of
\(\Sigma\)-protocols". We just run \(M\) cases of Back's LSAG and
combine them with a single \(e\) hash challenge at each key index (so
the hash challenge kind of "spans over the inputs"). Additionally,
note that the hash challenge here is assumed to include the keyset with
a generic \(L\) (limiting tiresome subscripting to a minimum...).&lt;/p&gt;
&lt;p&gt;To sign \(M\) inputs each of which have \(n\) keys:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For each input, define key image \(I_i
    =x_{i,\pi}\mathbb{H}(P_{i,\pi}) \ \forall i \in 0 \ldots
    M-1\);&lt;/li&gt;
&lt;li&gt;Set \(k_{i, \pi} \stackrel{\$}{\leftarrow} \mathbb{Z}_N \
    \forall i \in 0 \ldots M-1\)&lt;/li&gt;
&lt;li&gt;Form the hash-challenge at the next index: \(e_{\pi+1} =
    H(m||L||k_{0, \pi}G||k_{0,
    \pi}\mathbb{H}(P_{0,\pi})||k_{1, \pi}G||k_{1,
    \pi}\mathbb{H}(P_{1,\pi}) ...)\)&lt;/li&gt;
&lt;li&gt;Pick \(s_{i, \pi+1} \stackrel{\$}{\leftarrow} \mathbb{Z}_N\
    \forall i \in 0 \ldots M-1\); then:&lt;/li&gt;
&lt;li&gt;\(R_{i, \pi+1} = s_{i, \pi+1}G - e_{\pi+1}P_{i, \pi+1}\)
    and \(R\^{*}_{i, \pi+1} = s_{i, \pi+1}\mathbb{H}(P_{i,
    \pi+1}) - e_{\pi+1}I_i \ \forall i \in 0 \ldots M-1\)&lt;/li&gt;
&lt;li&gt;Calculate the next hash-challenge as \(e_{\pi+2} =
    H(m||L||R_{0, \pi+1}||R\^{*}_{0,\pi+1}||R_{1,
    \pi+1}||R\^{*}_{2,\pi+1} ...)\)&lt;/li&gt;
&lt;li&gt;Etc...&lt;/li&gt;
&lt;li&gt;Logic as for AOS, LWW but duplicated at every input with single
    \(e\)-challenge, and at signing index for all inputs (\(\pi\)):
    \(s_{i, \pi} = k_{i, \pi} + e_{i, \pi}x_{i, \pi}\ \forall
    i \in 0 \ldots M-1\).&lt;/li&gt;
&lt;li&gt;Signature is published as \(\sigma_{L}(m) = (s_{0,0} \ldots
    s_{0,M-1}, \ldots, s_{n-1,0}, \ldots s_{n-1,M-1}, e_0, I_0
    \ldots I_{M-1})\).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note:&lt;/p&gt;
&lt;p&gt;(1)  This algorithm as described requires each input to have the genuine
signer at the same key-index in the set of pubkeys for each input, which
is a limitation.&lt;/p&gt;
&lt;p&gt;(2) Monero has implemented Confidential Transactions, and this is
folded in with the above into a new design which seems to have two
variants "RingCTFull" and "RingCTSimple". This can be investigate
further in the documents on RingCT as referenced in the previously
mentioned
&lt;a href="https://ww.getmonero.org/library/Zero-to-Monero-1-0-0.pdf"&gt;ZeroToMonero&lt;/a&gt;.&lt;/p&gt;</content><category term="waxwing's Blog"></category><category term="cryptography"></category><category term="bitcoin"></category></entry></feed>